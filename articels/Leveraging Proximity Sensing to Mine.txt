2016 IEEE International Conference on Pervasive Computing and Communications (PerCom)

Leveraging Proximity Sensing to Mine
the Behavior of Museum Visitors
Claudio Martella∗ , Armando Miraglia∗ , Marco Cattani† , Maarten van Steen‡

∗ VU

† Delft University of Technology,
‡ University of Twente
University Amsterdam,
Email: c.martella@vu.nl, a.miraglia@student.vu.nl, m.cattani@tudelft.nl, m.r.vansteen@utwente.nl

Abstract—Face-to-face proximity has been successfully leveraged to study the relationships between individuals in various
contexts, from a working place, to a conference, a museum, a
fair, and a date. We spend time facing the individuals with whom
we chat, discuss, work, and play. However, face-to-face proximity
is not the realm of solely person-to-person relationships, but it
can be used as a proxy to study person-to-object relationships as
well. We face the objects with which we interact on a daily basis,
like a television, the kitchen appliances, a book, including more
complex objects like a stage where a concert is taking place.
In this paper, we focus on the relationship between the visitors
of an art exhibition and its exhibits. We design, implement,
and deploy a sensing infrastructure based on inexpensive mobile
proximity sensors and a ﬁltering pipeline that we use to measure
face-to-face proximity between individuals and exhibits. Our
pipeline produces an improvement in measurement accuracy of
up to 64% relative to raw data. We use this data to mine the
behavior of the visitors and show that group behavior can be
recognized by means of data clustering and visualization.

I. I NTRODUCTION
Museum staff design exhibitions to educate, engage and
entertain the visitors. Yet, museums rely on surveys and
expensive observational studies to collect coarse-grained information about the response of their visitors, with limits
of scalability and bias. Central to the understanding of how
visitors interact with an exhibition is the identiﬁcation of which
exhibits individuals stop at, for how long, and in which order.
According to an ethnographic observational study of visiting
styles at the Louvre museum, visitors can be classiﬁed into
four classes according to their movements [1]. For example,
one class of visitors follows a speciﬁc path spending a lot of
time at almost all exhibits, while another class seems to have
a speciﬁc preference for some known exhibits at which they
spend a lot of time, ignoring the others. This classiﬁcation
has been used, based on activity logs coming from a digital
museum guide, to help engage museum visitors and avoid information overload [2]. Characterizing and quantifying visitors
behavior helps museum staff evaluate their curatorial decisions,
reporting to stake holders and funders, and building data-driven
marketing campaigns and applications.
The key to collecting this information is the ﬁne-grained
measurement of face-to-face proximity between visitors and
exhibits. We call positioning the problem of identifying which
exhibit an individual is facing at short distance. Existing approaches are not suitable for this problem. Indoor localization
technologies estimate the absolute position of an individual in
space, without measuring where the individual is looking at.
This means that positioning an individual at the closest artwork
within a given distance can produce false positives if the

978-1-4673-8779-8/16/$31.00 ©2016 IEEE

individual has her back towards the exhibit or if she is facing
an artwork nearby. Moreover, only very few existing state-ofthe-art techniques achieve, in optimal controlled environments,
an error of less than 2 meters. With such errors, positionings
of the visitor at a wrong exhibit, including those at the other
side of a wall, would be frequent. Finally, these techniques
often require expensive investments and rely on complex setup
procedures each time exhibits are re-arranged.
Contributions. In this paper, we propose a technique based
on inexpensive and energy-efﬁcient mobile proximity sensors,
and a ﬁltering pipeline to accurately position visitors at exhibits
at all times. While we use radio-based proximity sensors, our
ﬁltering pipeline is not bound to any particular technology
and does not require, for example, measuring distance from
exhibits or expensive setups. In particular, we introduce a
particle ﬁlter tailored to the problem of positioning, together
with two smoothening ﬁlters that increase measurement accuracy. We use positionings to reconstruct the time spent at
exhibits and the visitor path, deﬁned as the ordered sequence
of exhibits visited by the individual. We evaluate the approach
with data collected from 182 volunteers during a real-world
experiment. We show that by clustering this data we can
identify group behavior, such as common paths and patterns
of time distribution at exhibits.
The remainder of this paper is organized as follows.
First, we give an overview of our system, including sensing
infrastructure, ﬁltering pipeline, and data analysis. Then, we
discuss related work regarding localization systems and museum technology. After describing our model and pipeline, we
evaluate the accuracy of our measurements, and apply standard
data mining techniques to the data. Finally, we conclude with
a discussion about limitations and future work.
II. OVERVIEW
We conducted a 5-days experiment spread across 2 weekends at the CoBrA Museum of Modern Art (CoBrA). Our data
collection focused on the temporary exhibition entitled “The
Hidden Picture”, a curated sample of the corporate collection
of ING. The exhibition was displayed in the dedicated open
space at the top ﬂoor of the museum. The space is conﬁgurable,
and divider walls were used to separate the space into 6 “open
rooms” dedicated to different themes. The overall space was
about 100 meters long and 25 meters wide, with a ceiling
reaching about 5 meters, while divider walls were some 3.5
meters high.
Rooms 1 and 2 focused on ﬁgurative art, rooms 3 and 4
mostly on abstract art, room 6 on pieces inspired by nature,
for a total of 60 pieces. The pieces varied in size, style and
medium, including photos, paintings, sculptures, videos, and

an installation with a cage hosting a living chameleon. None
of the pieces were highly famous, and were hence appealing
the visitors based on immediate reaction rather than on prior
knowledge. Of the 60 pieces, we instrumented 45 exhibits with
our sensing infrastructure.
A. Data Collection Architecture
We designed a system based on inexpensive radio-based
proximity sensors. Our sensing solution is compliant to the
Zigbee standard and it can be implemented for example
through Bluetooth low energy (BLE) beaconing, available in
modern smartphones. To give us freedom to investigate our
solution, instead we deployed ad-hoc devices running a dutycycled MAC protocol [3] that allows us to run our system for
weeks with a single battery charge.
The sensing infrastructure comprises mobile devices and
anchor points (or simply anchors). Mobile devices are sensor
nodes worn by the visitors. They are attached to a lanyard
worn around visitors’ neck and hang on the chest. Due to the
shielding effect of the visitor’s body, the radio communication
range is steered to the front with a controlled angle of around
90 degrees and some 2-3 meters of distance. Anchors are sensor nodes positioned at the base of each exhibit. We installed
anchors inside of enclosure aluminium boxes designed to shape
the communication range to approximately 60 degrees and 2-3
meters of distance. With this setup, mobile devices and anchors
can communicate only when the visitor is facing an exhibit.
Every second, anchors transmit through the radio a unique
anchor identiﬁer (AID) that is received and timestamped by
mobile devices within range. We consider the reception of an
AID by a mobile device a proximity detection. Note that our
sensors do not measure radio signal strength (i.e., RSSI). While
it does not enable us to measure distance between points, it
allows a cheaper and more energy-efﬁcient solution. Every
second, mobile devices transmit the list of detections received
during the previous second together with their unique mobilepoint identiﬁer (MID) to a longer range of approximately 100
meters, which are received by one or more sinks.
Sinks are computers that receive mobile devices transmissions through the same type of sensor node used for
anchors and mobile devices, and store the timestamped lists
of detections in a central repository. Sinks are installed in
various areas of the exhibition space to ensure full coverage
and some degree of overlap. Note that due to the overlap of
the areas covered by the sinks, mobile devices transmit their
messages together with a randomly generated number that we
use together with timestamps to remove duplicate detections
from the database.
When a mobile device is handed out anonymously to a
visitor, the visitor is assigned a unique user identiﬁer (UID)
that is associated to the corresponding MID. Each visitor
check-in and check-out times are stored together with the UIDMID mapping. Our raw data database comprises this mapping
and the list of timestamped detections collected by sinks.
B. Data Filtering Pipeline
The raw database of proximity detections is characterized
by a number of shortcomings that obstacle a direct use for visitor positioning without prior ﬁltering. Accurately computing
which artwork, if any, a visitor is facing at each second based

solely on raw data is not possible for a number of reasons,
related to the irregularity of wireless communications and the
imperfect steering of our enclosures.
We designed a data ﬁltering pipeline to estimate, for each
second of a visit, at which artwork a visitor is positioned and
the sequence of exhibits that deﬁnes such visit. The pipeline
comprises three steps. First, we ﬁlter the data with a particle
ﬁlter. We have developed a technique based on particle ﬁlters
that takes into account the topology of the exhibition room, the
placement and directionality of the anchors, and the movement
of the visitor. Note that our technique positions the visitor
at exhibits and does not compute absolute coordinates, like
traditional techniques based on particle ﬁlters designed for
localization.
Second, visitor-exhibit mappings are further ﬁltered with
a density-based ﬁltering algorithm that corrects occasional
artifacts introduced by the particle ﬁlter. While the particle
ﬁlter drastically increase positioning accuracy, there are still
occasions where a large number of missing detections can
cause gaps in positioning data, making it appear as a visitor
would return at an exhibit repeatedly in a short window of
time (with some seconds in between where the visitor appears
having left the exhibit either for the center of the room or, more
rarely, for an exhibit nearby). The ﬁltering algorithm ﬁlls these
gaps and ignores spurious positioning data.
Third, we extract through a majority voting ﬁlter the
sequence of AIDs at which the visitor was positioned. The
ﬁlter scans a visitor positioning data to detect transitions from
exhibit to exhibit, and disambiguating situations where a visitor
may appear facing two exhibits at the same time. During this
step we also reconstruct the path followed by the visitor, that
is the sequence of stops at exhibits followed by the visitor.
C. Data Analytics Applications
Once raw data has been processed by our pipeline, we
obtain for each visitor a vector rv of N elements, each
representing the number of seconds spent at each of the N
anchors/exhibits, and a sequence sv of AIDs to represent the
path followed to visit the exhibits. If an exhibit was never
visited by the volunteer, the corresponding element of rv will
contain a value of 0, and the corresponding AID will be
missing in sv .
We can leverage these two data structures to mine the
behavior of all the visitors and discover behavioral patterns,
like popular rooms and exhibits, common paths followed
through the exhibition. Furthermore, if group behavior did
emerge during the exhibition, one can leverage historical data
of past visitors to predict the behavior of future visitors, from
time spent at exhibits to their satisfaction.
III. R ELATED W ORK
Our work is closely related to the topic of indoor localization. A recent evaluation of 22 indoor localization mechanisms [5] provides us several insights on how state-of-the-art
localization techniques could perform in our scenario.
Among all localization mechanisms, only three [6], [7], [8]
achieved an error of less than 2m, while only half achieved an
error of less than 3m. Moreover, localization errors increase
signiﬁcantly (both in terms of average and deviation) at the
edges of rooms and in hallways, were most museums have

exhibits. For our application, this is quite a signiﬁcant error
since the distance between exhibits is usually just few meters. Differently from localization techniques, our mechanism
provides a deployment density that matches the placement of
exhibits. In other words, by design we tailor our positionings
where needed.
Moreover, because museums often have exhibits on both
sides of walls, this lack of accuracy produces an even larger
error when used for positioning (e.g. positioning a visitor at
a painting in the next room or even worse on the next ﬂoor).
Our combination of enclosures and a tailored particle ﬁlter
allows us to focus on face-to-face proximity and minimizes
these errors. Furthermore, localization systems are usually
evaluated in controlled settings and do not account for the
variability introduced by people or by changes in the furniture
setup, both typical aspects of temporary exhibitions. In more
realistic conditions, the localization error of the tested indoor
techniques increase by approximately 1.5m to 4m.
There are mainly two types of system. Infrastructure-free
mechanisms [7], [8], [9] exploit the existing Wi-Fi access
points and require a lengthy calibration phase (ﬁngerprinting)
that must be repeated every time the environment signiﬁcantly
changes. In case of a museum, this means every time the exhibition changes. Infrastructure-based approaches, on the other
hand, usually require a one-time deployment of a hardware
infrastructure that can be expensive and that could affect other
practical issues such as aesthetics and safety certiﬁcations.
Instead of ﬁngerprinting the radio environment, which is
susceptible to changes in the environment, most infrastructurebased techniques exploit the propagation speed (time-of-ﬂight)
of radio [10], [11] and sound [12], [13] to estimate the distance
of visitors from the anchor and triangulate their position.
Interesting to note, the only localization technique able to
achieve sub-meter accuracy [6] is not based on time-of-ﬂight,
but on the signal’s phase offset, and took several years (5)
of development to provide such accuracy. Being based on a
proprietary hardware, this technique is difﬁcult to generalize
and apply, for example, to smartphone platforms.
Our technique, on the other hand, is generic and based only
on face-to-face proximity, that is fuzzy and hard to predict by
nature. In particular, since our mechanism does not require to
sense the signal characteristic such as the strength or the phase
offset, it can be applied to several protocols (e.g. ZigBee, WiFi,
Bluetooth, etc.) and even different mediums (e.g. radio, sound
and light).
Few sensor-based systems have been used to study the
behavior of visitors of art exhibitions, in relation in particular
to their movements. Early attempts made use of indoor localization systems based on Bluetooth data collected from mobile
phones, to trace the movement of visitors between rooms [14].
This data can be used, for example, to support multimedia
guides [15], [16], but it captures only which room (or part of
it) an individual is visiting. More recently, data coming from
indoor localization and physiological sensors has been used,
together with entrance and exit surveys, to study the cognitive
reaction and social behavior of a number of individuals in an
exhibition [17].
A similar device to measure position and spatial orientation
(i.e., through a compass) of the individuals has been used to
study the behavior of visitor pairs in a museum. The study

presents a system to classify pairs early in the visit into one of
six classes, to provide socially-aware services to the pairs, for
example to increase their engagement with the exhibition [18].
This study focuses on the interaction between the individuals
and does not attempt to position the pairs at exhibits.
To summarize, none of these approaches tackles the problem of ﬁne-grained face-to-face positioning, and rely either on
coarse-grained room-level positioning or on absolute localization without attempting to position visitors at exhibits.
IV. M ODEL
We consider a visitor wearing a mobile device v for a
duration of T seconds. The exhibition comprises N exhibits,
each instrumented with an anchor ai ∈ A = {a1 , a2 , . . . , aN }.
For each visitor v we represent the set of proximity detections
as a N × T matrix Dv , where Dv (i, j) = 1 if and only if the
mobile device v detected anchor ai at time j. Dv (∗,t) refers
to all detections collected at any time t, and Dv (i, ∗) to all
detections of ai . Similarly, we deﬁne a positioning matrix Mv
as a N × T matrix, where Mv (i,t) = 1 if and only if visitor
v was facing exhibit ai at time t within a distance smaller
than d (i.e., the sensor detection range, in our case 3m.). The
deﬁnition of Mv is analogous to the deﬁnition of a series of
proximity graphs [4], with the additional constraint of a visitor
being in proximity of maximum one anchor at any time t. Note
that there can be times t such that v is not positioned at any
exhibit. These are the times when a visitor is walking around
the museum or too far to be detected.
A. Problem deﬁnition
Our goal is to compute the positioning matrix Mv from the
detection matrix Dv . Ideally, if v was facing al from second
i to second j within distance d, we would have Dv (l, k) = 1
for i ≤ k ≤ j for only al . In other words, Dv would contain
detections for the whole duration of the face-to-face proximity
between v and al , and there would be only one al for a given
time k such that Dv (l, k) = 1. With these perfect conditions,
matrix Dv would contain a continuous stream of detections
between v and the anchors, and it could be directly used as
positioning matrix Mv . However, in practice this is not possible
for the following reasons.
First, the database is missing detections. Transmissions
between anchors, mobile devices, and sinks can be lost due
to many factors, such as message collisions and low signal-tonoise ratios [19], [20]. In other words, while a visitor faces an
exhibit, sinks collect a bursty stream of detections with gaps.
Second, although we control the communication range of
the anchors with our enclosures, it is still possible for a mobile
device to detect multiple anchors at the same time. A typical
scenario is when two anchors are positioned close-by and the
visitor stands in an area of overlap between the two anchors’
transmission ranges. Looking at the instantaneous raw data
does not allow disambiguation of these occurrences. Note that
this problem could occur also between anchors positioned at
the two sides of a wall, causing a visitor to be in proximity of
exhibits installed in two different rooms at the same time.
Third, a mobile device can detect an anchor at a distance
larger than the expected transmission range, either due to a
corrupted AID in the anchor message (typically caused by a
collided message passing a CRC), or due to some tunneling

effect in the wireless transmission. This is perhaps the problem
occurring less frequently.
We hence deﬁne our pipeline as the set of operations to
ﬁlter and transform Dv into a Mv for any given visitor v.
B. Particle Filter
We designed and implemented a ﬁlter based on particle
ﬁlters to tackle two challenges related to our positioning
problem: (i) due to unreliable wireless communication, some
detections could be missing, and (ii) due to the multipath
effect, a mobile device could detect multiple anchor points,
even far away and on the other side of a wall.
Particle ﬁlters have been successfully used in localization
to estimate the absolute position of individuals with unreliable
sensors [21], [22]. For localization, usually a mobile sensor
communicates with a few anchors installed at known locations.
It is assumed that the sensor can communicate with all, or
a majority of, anchors from all positions and directions, and
that the sensor can measure distance from these anchors, for
example through signal strength or time-of-ﬂight.
Our setup does not match these assumptions, as we deploy
many anchors that communicate only directionally and at short
range, without the capability to measure distance. Moreover,
we would expect, and to a certain extent desire, mobile devices
to detect only one anchor at each time, if any, that is the one
in front of the visitor. In other words, our system was designed
for the problem of positioning, therefore we need to design a
particle ﬁlter that reﬂects the characteristics of our setup and
problem.
The ﬁlter requires topology information about the exhibition. In particular, a set of anchors A = {a1 , a2 , . . . , aN } each
characterized by a position x, y and an orientation α, and a
set of walls W = {w1 , w2 , . . . , wM }, each deﬁned as a segment
between two points, to describe the layout of the exhibition
space. We deﬁne the set of particles P = {p1 , p2 , . . . , pK }, each
deﬁned by a position x, y and a weight w (the likelihood of
a particle to represent the actual visitor’s position). Initially,
particles are distributed uniformly at random across the layout
of the exhibition space.
Given a detections matrix Dv , the particle ﬁlter comprises
four steps that are executed for each time t of the visit, with
0 ≤ t < T.
• Estimation: We compute the likelihood of each particle’s
estimate (i.e., its position) given the measurement at time
t, that is the set of detections in Dv contained in the t-th
column . For each particle p, its weight is computed using
the likelihood function w = Φ(p, Dv (∗,t)). More details
about this function are given later in the text.
• Positioning: We estimate the position of v by computing
the weighted average among the particle coordinates (i.e.,
the centroid) and ﬁnd the closest anchor ai . We then set
Mv (i,t) = 1, unless the variance of the particle coordinates
from the centroid is larger than a threshold, meaning that
the conﬁdence of the estimate is low.
• Re-sampling: We create a new set of particles by drawing with replacement from the current weighted set of
particles. While drawing particles from the set, we favor
particles proportionally to their weight (i.e., their likelihood). As a result, particles with higher likelihood are
picked more often than particles with lower likelihood.

Fig. 1. The landscape of the multivariate gaussian kernel used to compute the
likelihood function Φ. For displaying purposes, we assume all anchor points
were detected at time t. Note that the likelihood function takes into account
angle and distance from anchors, as well as overlap between detection ranges.

If all particles are improbable, we generate new ones at
random.
• Movement: We move particles at walking speed in random directions, avoiding illegal moves, such as walking
through walls.
An important component of our system is the function
to compute the likelihood of a particle’s estimate. Intuitively,
because our sensors are steered to measure face-to-face proximity, we want a particle to have higher likelihood if it is
positioned in front of a detected anchor and if it is at close
distance. We deﬁne Φ(p, Dv (∗,t)) as a multivariate function
based on a Gaussian kernel with maximum likelihood at 1
meter distance and at 0 degrees angle from the anchor (exactly
in front). The likelihood is deﬁned as 0 for distances beyond
3 meters and angles larger than 30 degrees. When multiple
detections are present, we mix the likelihood functions of the
involved anchors by summing their values. In those cases, the
likelihood function computes a multi-lateration between the
detected anchors.
For displaying purposes, Figure 1 shows the landscape of
Φ assuming that all anchors are detected at the same point in
time. In case only one anchor is detected, one can imagine
the landscape to have values larger than 0 only in front of
the anchor. Note that artwork 42 was a cage, positioned
far from the walls, of which visitors could walk around.
For this reason, we placed the sensor inside an enclosure
that allowed detections from any angle, still within the same
distance as deﬁned for the other artworks. The function models
directionality and range of both mobile devices and anchors,
leveraging the radio directionality due to the enclosures.
The ﬁlter keeps positioning a visitor at the last exhibit
during gaps of missing detections. As soon as particles spread
too much due to their random movements, the ﬁlter assumes
the visitor is far from any exhibit. Similarly, spurious detections from anchors far away or at the other side of a wall
are ignored as it takes time for particles to reach them (e.g.
without crossing walls), and hence for their likelihood to be
affected by those anchors.
C. Density-based Filter
The particle ﬁlter computes the positionings of a visitor
regardless of missing, wrong, and ambiguous detections. The
resulting matrix Mv contains for each anchor a series of bits
that tells us whenever a visitor was facing an anchor at a certain
time. While smoothened by the particle ﬁlter, the series in
Mv can still present gaps, for example, during short periods

where particle conﬁdence was too low (wrongly, due to many
missed detections), or when a visitor was wrongly associated
to a nearby exhibit. Even though they are rare, we want to
remove these artifacts by further smoothening Mv through a
density-based ﬁlter. In principle, the density-based ﬁlter acts
analogously to a low-pass ﬁlter implemented through a sliding
window, but it is able to compute the optimal values for the
parameters corresponding to window size and threshold.
The density-based ﬁlter [23] ﬁrst analyses all the series
in Mv to compute the k-nearest neighbors statistics for each
positioning, and it then uses these statistics to automatically
identify bursts of bits through the density-based clustering
algorithm DBSCAN [24]. Each identiﬁed cluster is effectively
a period of time when the visitor was continuously facing
an exhibit. Once clusters are identiﬁed, we can ﬁll the gaps
within the clusters. Note that, at the same time, the clustering
algorithm classiﬁes positionings that are isolated and not part
of any cluster as noise. The result is a new positioning matrix
Mv that is effectively a smoothened version of Mv .
Note that, differently from Mv , in Mv visitor v can be
positioned at multiple anchor points for the same time t, as
series are ﬁltered independently. We solve this problem in the
next, and last, step of the pipeline.
D. Majority-voting Filter
We deﬁne a majority-voting ﬁlter to disambiguate those
times in Mv when we position v at more than one anchor
(i.e., those columns of Mv that have more than one row
with a value of 1). The majority-voting ﬁlter looks at a
window of duration of L seconds ahead of, and including,
t to decide at which anchor to position v. The ﬁlter decides
by choosing the anchor with the largest number of positionings in that window of time. Formally, we let N windows
w j,L,ai = M  (i, j), M  (i, j + 1), . . . , M  (i, j + L) slide in parallel
over the series (i.e., rows) in Mv , with 0 ≤ j < T − L. We break
ties by picking the anchor chosen at the previous slide, or at
random when no anchor was chosen at the previous slide (i.e.,
when all windows contain all zeros). While we ﬁlter Mv we
create a new positioning matrix Mv and a path sequence sv of
anchor AIDs that represents the order used to visit the exhibits.
We consider v to have transitioned to a new exhibit when the
ﬁlter positions v at an anchor different from the previous.
To summarize, for each visitor v, the pipeline outputs (i)
the positioning matrix Mv representing at which anchor v was
positioned, if any, at each time t, and (ii) the sequence sv
of anchors AIDs that represents in which order v visited the
exhibits. Note that not necessarily all anchor are present in sv
and also that an anchor AID can appear multiple times, though
not consequently, in sv . Finally, we can compute a vector rv
of length N, that represents the number of seconds spent by
the visitor facing each exhibit. More precisely, we compute
T
the values of rv as rv [i] = ∑t=0
Mv (i,t), for 0 < i < N. We will
use rv and sv in Section VI to identify group behavior.
V. E VALUATION
A. Methodology
We organized two experiments at CoBrA to evaluate our
model and infrastructure. In a controlled experiment, we
scripted 28 visits and asked volunteers to follow the instructions through the script with a timer. The script deﬁned a visit

as a sequence of stops at exhibits, each characterized by a
time of arrival and a time of departure from each exhibit.
Volunteers were asked to stay at some 1-2 meters of distance
and facing the exhibit for the whole duration of each stop.
For this experiment, we focused on Room 4 only. While we
focused on a subset of the exhibits, we kept all anchors on at
all times, including those at the other side of the walls.
In a real-world experiment, we asked the visitors of the
museum to volunteer in the experiment by wearing one of our
sensors during their visit. Volunteers were not instructed or
scripted in any way, and could move freely in the exhibition
space for the whole duration of their visit. A total of 182 volunteers decided to participate, spread over the 5 days of duration
of the real-world experiment. Two human observers collected
ground truth positionings for 19 volunteers, by annotating
arrival and departure times at each exhibit (corresponding to
Mv ), and the order used to visit exhibits (corresponding to sv ).
Setups. A the end of the experiments, we processed the
data collected by the sinks in the central repository. We
utilized the same sensing infrastructure, i.e., the sensors and
the enclosures, as well as the same ﬁltering pipeline for
both experiments. For the particle ﬁlter, we utilized 1000
particles and set the particle speed to 1m/s. Density-based ﬁlter
parameters were chosen as described in [23] by choosing the
knee point of the k-distance plot, corresponding to ε = 15 for
minPts = 2. We chose a window size L = 10 that we chose
empirically as it would maximize accuracy of both positionings
and paths, though results did not vary signiﬁcantly in the
interval [5, 30].
Metrics. To measure the performance of our solution at
the task of positioning visitors at the exhibits we compute the
number of:
• False positives (FP): positionings that are present in the
measurement but not in the ground truth.
• False negatives (FN): positionings that are present in the
ground truth but not in the measurement.
• True positives (TP): positionings that are present in the
measurement and in the ground truth.
• True negatives (TN): positionings that are missing in the
measurement and in the ground truth.
We compute these values by comparing Mv and the ground
truth for each annotated (or scripted) volunteer. We use these
tests to compute two statistical measures of performance for
binary classiﬁcation tests. Sensitivity can be used to measure
the ability of the test to identify positive results and is deﬁned
TP
as sensitivity = T P+FN
. Speciﬁcity can be used to measure the
ability of the test to identify negative results and is deﬁned
TN
as speciﬁcity = T N+FP
. Intuitively, they measure the ability
to correctly estimate positioning and its absence, respectively.
Balanced accuracy, used in cases of unbalanced classes such as
ours (where true negatives are much more frequent), is deﬁned
as the arithmetic mean of sensitivity and speciﬁcity.
To measure the performance of our solution at the task
of computing paths, we compared paths extracted through our
method with paths extracted from the ground truth. To this end,
we use two types of metrics: sequence-based and coordinatebased metrics.
Sequence-based. We used two metrics designed to compute
similarity between sequences. The ﬁrst metric is the JaroWinkler (Jaro) [25] similarity metric, which is used to compute

39

45

41

40

0

4

3

5

1
38

2

42

10

9
37

36

33

35

43

44

30

31

26

32

34

29

7

6
22

23

25

8
20

11

19

18

12

16 15 14 13

17

24

27

28

21

Fig. 2.
The mesh used as layout to compute paths between paintings.
The planimetry is split in cells, each one mapping 1 square meter of the
layout space. Red dots labeled with a number represent artworks. Walls are
represented as disconnected dots in the mesh. The circular gap in the uppercentral part of the mesh is due to a non-walkable atrium.
1.0
0.8
Score

0.6

0.4
0.2
0.0

1

2

3

4

5

6

7

Anchor IDs

8

9

10

11

Sensitivity
Specificity
12

(a) Controlled experiment
1.0
0.8
Score

0.6

0.4
0.2
0.0 1

Sensitivity
Specificity
2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 36 37 38 39 40 41 42 43 44 45

Anchor IDs

(b) Real-world experiment
Fig. 3. Anchors sensitivity and speciﬁcity values for the two experiments
across annotated/scripted visitors. For the controlled experiment, some anchors
have no sensitivity because no stops were scripted at those anchors (they were
positioned at the other side of walls of anchors involved in the experiment).

string similarity. Jaro is a type of string-edit distance that considers explicitly the mismatch in the order in which elements
appear in two sequences (an operation called transposition) and
how far mismatching elements are in the sequences. Intuitively,
inverting in sv the order of two exhibits that are nearby in the
sequence is less penalized than inverting two exhibits far from
each other in the sequence (e.g. jaro(“ABCDE  , “ABCED ) >
jaro(“ABCDE  , “AECDB )). The second metric is the
Ratcliff-Obershelp (Sequencematcher) [26] matching metric,
which is used for pattern recognition and is less forgiving
when inverting nearby elements. Sequencematcher matches
recursively the elements in the longest-common-subsequences
between two given sequences. Both metrics compute a value
between 0 and 1, with 1 representing perfect similarity and 0
representing no match.
Coordinate-based. We used a metric designed to compute
the distance between two sets of coordinates. Hausdorff distance measures how far two subsets of a metrics space are
from each other. Intuitively, two sets of coordinates are close
if every point in one set is close to some point in the other
set. More precisely, Hausdorff is deﬁned as the longest distance
from a point in one set to the closest point in the other set.
While Hausdorff distance is originally deﬁned on the longest
distance, often the mean and median distance are also used to
gain a better picture of the distance between the two sets. We
generate a set of coordinates from a sequence sv as follows.

We create a mesh by splitting the layout of the exhibition
space in 1m2 cells. Mesh edges represent cell edges, and mesh
vertices represent cell vertices. In addition to cell edges, we
also connect vertices through edges representing cell diagonals.
We do not allow edges crossing walls. Every vertex in the
mesh has an associated coordinate that depends on its position
when overlayed on the exhibition space layout (with the (0, 0)
vertex being positioned at the top-left of the layout). Figure 2
shows the mesh. We compute the shortest paths between each
pair of adjacent elements in sv and we concatenate the list of
coordinates associated with the vertices in the shortest paths.
This way, we obtain a representation of the path in space that
visitor v would have followed while performing sv , had she
followed the shortest one.
While we do not expect the visitor to have walked precisely
through those coordinates, we used also a coordinate-based
metric to better measure the impact of errors in sv . A missing
or wrongly added anchor in sv may result in a single string
edit operation of Jaro that does not capture whether the visitor
was positioned far away in space from the correct anchor,
for example, on the other side of a wall compared to the
anchor 1 meter away. Introducing a coordinate-based metric
allows us to understand the impact of our errors in relation
to the placement of the anchors in the exhibition space.
Moreover, this metric allows us to understand the accuracy of
path visualizations, as two subsequences with low Hausdorff
distance (e.g. if we miss an anchor by positioning the visitor at
the anchor 1 meter away) look very similar, often enough for a
visualization, regardless of having potentially a low sequencebased similarity.
B. Results
Positioning. Figure 3 presents the mean values and standard deviations of sensitivity and speciﬁcity for each anchor.
The average sensitivity across the anchors for the controlled
and real-world experiments was 0.73 (std 0.02) and 0.61 (std
0.04) respectively, while the average speciﬁcity was respectively 0.944 (std 0.002) and 0.981 (std 0.001), for a balanced
accuracy of respectively 0.84 and 0.79. Note that the pipeline
increases balanced accuracy by 42% in the case of the realworld experiment, and by 63% in the case of the controlled
experiment, compared to using raw detections as positionings.
We can notice that most errors are caused by false negatives, as the values of speciﬁcity are very close to the maximum
value of 1.0, while sensitivity values are smaller and vary
more. This can be expected to be caused by missing detections,
which are more likely than false positives. Moreover, reaching
very high sensitivity may be extremely difﬁcult due to the
method used to collect ground truth. As visitors face exhibits
for short periods of time (on average around 15 seconds), a
small annotation error can impact substantially the sensitivity
metric. Observers were asked to start timing a positioning at an
anchor when the visitor was facing the exhibit from a distance
of some 2-3 meters, but it is difﬁcult for the observer to identify
the exact moment the visitor is at range and facing the exhibit.
An error of 1-2 seconds about arrival and departure times by
the observers can mean missing 10 − 20% of the true positives.
Moreover, often visitors moved during their time at exhibits, getting close and further from the exhibit, temporarily
facing somewhere else to discuss with an another visitor or to
approach an information sheet attached to a wall nearby the

distance similarity score

1.0
0.8
0.6
0.4
0.2
0.0

jaro

1

2

3

4

5

6

7

sequencematcher

8

9

10

11

12

13

14

15

16

17

hausdorff-max

18

19

20

21

22

23

24

25

hausdorff-mean

26

27

hausdorff-median

28

100

10-1

1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28

Visitor IDs

1

2

3

4

5

6

7

8

9 10 11 12 13 14 15 16 17 18 19

Visitor IDs

Fig. 4. Sequence-based similarity values (top) and coordinate-based distance (bottom) for the controlled experiment (left) and the real-world experiment (right).
We plot coordinate-based distance in log-scale.

exhibit. It is almost impossible for the observers to include all
these ﬁne-grained elements in their annotations. This hypothesis is conﬁrmed by the increased accuracy obtained with the
controlled experiment, though also in the case of scripted visits
it is difﬁcult for visitors to consistently approach and depart
the detection range correctly with second-level precision as
deﬁned by the script.
Some sensors in denser areas reach often either very low or
very high sensitivity, while variance is lower in areas of lower
density. This can be an expected effect of the last stages of the
pipeline, where smoothening ﬁlters favor certain anchors in a
winner-takes-all fashion, perhaps due to a favoring conditions
of the enclosures position and orientation (e.g. exhibits 5,
13 and 34). This happens less frequently between anchors
positioned more distantly from each other.
To investigate the impact of the variability in the sensitivity
we ranked the artworks by the amount of time spent in total by
all annotated visitors facing them. We ranked exhibits based
on the measurement and on the annotations. Intuitively, we
would expect the two rankings to be similar if the measurement was accurate enough regardless of variance in missed
positionings (i.e., we miss some positionings but we can still
order the exhibits by time correctly). We computed Spearman
rank correlation between the two rankings to see whether we
can capture the relative relationships between anchors. The
correlation values for the whole ranking was 0.413 with a
p-vaule of 0.01. We then computed correlations for the top
N exhibits for N = 5, 10, 15, 20, yielding respectively correlations values 0.996(p = 0.0002), 0.768(p = 0.009), 0.65(p =
0.008), 0.544(p = 0.005). These results show that errors are
accumulated at the tail of the ranking, where time spent at
exhibits are more similar and hence easier to mistake. We
would expect to converge to better results with a sample larger
than the 19 annotated individuals.
Paths. Figure 4 shows sequence-based similarity and
coordinate-based distance values for both experiments, with
values for each annotated or scripted visitor. The average
Jaro similarity across visitors for the controlled and realworld experiments was 0.879 (std 0.08) and 0.716 (std 0.05)
respectively, while Sequencematcher similarity was 0.814 (std
0.09) and 0.613 (std 0.05) respectively. The average sequence
lengths were respectively 8.147 for the controlled experiment
and 36.316 for real-world experiment. The measures show that
we are able to accurately reconstruct path sequences, even
when they are long. Moreover, higher values of Jaro similarity
conﬁrm that sometimes we invert nearby anchor points in

sequences.
Regarding coordinate-based distance, the average (max,
mean, median) values of Hausdorff distance for the controlled experiment and the real-world experiment were
(1.186, 0.317, 0.137) and (5.002, 0.825, 0.245) respectively.
Mean and median submeter error show that we consistently
position the visitor correctly (or less frequently at an anchor
nearby), while a 5 meters maximum distance suggests that
worst errors cause a positioning of a visitor at a “walking”
distance of 5 meters.
VI. A PPLICATION
In this section we present the application of data mining
techniques applied to visitor data.
A. Methodology
We used the set of rv vectors and sv path sequences from
all 182 volunteers as dataset for two clustering tasks: (i)
identifying common paths chosen by visitors when visiting
the museum, and (ii) identifying patterns in the distribution
of visiting time across rooms and exhibits. For both tasks,
we utilize Hierarchical Agglomerative Clustering (HAC) [27],
a bottom-up clustering algorithm where items initially form
individual clusters and are merged in a series of iterations
based on a clustering criterion. We chose the Ward method [28]
as a criterion for choosing clusters to merge at each step, which
focuses on minimizing total within-cluster variance.
The input of the algorithm is the distance matrix between
all items in a dataset. To identify common paths, we compare
all sv sequences with Jaro (and use 1 − jaro(a, b) as Jaro
computes similarity while HAC requires distance). For the task
of identifying patterns of time distribution, we compute the
Euclidean distance between all rv vectors. Before computing
distances, we pre-process rv vectors as follows. First, we use
a threshold such that rv contains only elements larger than 15
seconds (that is we consider for each visitor only the exhibits
where she spent more than 15 seconds), and then we scale
and center each adapted rv . In other words, we transform rv
vectors into vectors describing how visitors distributed their
time, among those exhibits where they spent more than 15
seconds. We then fed both datasets to the same clustering
algorithm.
B. Results
Time distribution. In Figure 5(a) we show the distance
matrix between the rv vectors, which are organized according

(a) Hierarchical clustering of visitors based on time distribution

(b) distribution of visiting time at exhibits

Fig. 5. Hierarchical agglomerative clustering of visitor time distribution vectors. The clustering algorithm identiﬁes one small group (green in the dendogram)
that spent time mostly in room 6, and another major group (top) that is further clustered. Horizontal white lines show cluster divisions and black vertical lines
room divisions.

(a) Prototypical paths extracted from the largest cluster of volunteer

(b) Prototypical paths of volunteers visiting the exhibition in inverted order

Fig. 6. Visualizations of two groups of common paths identiﬁed through hierarchical agglomerative clustering of visitor paths, one (a) representing the common
trend among the largest group of visitors, and one (b) representing the 10% of visitors that visited the exhibition starting from the end.

to the result of the agglomerative clustering displayed in
the linkage dendogram (the dendogram shows how visitors
are grouped into clusters and the hierarchy of clusters), and
in Figure 5(b) we show the set of pre-processed rv vectors
grouped by the result of the clustering algorithm (vertical black
lines show room divisions and horizontal white lines show
cluster division). The results show that the clustering algorithm
identiﬁes two major clusters. The ﬁrst cluster includes the
bottom visitors (1-38, green in the dendogram) for their
particular interest in 3 artworks in room 6 and little interest in
room 1 except for exhibit 1. The second cluster includes all
visitors between (65-182) who spent time in room 1 and in
front of exhibit 36. This second cluster is further clustered in
other clusters, for example, (i) (85-118, violet) due to speciﬁc
interest in the last 3 exhibits, (ii) (124-160, yellow) due to
speciﬁc interest in exhibits 1, (iii) (160-182, black) due to
some speciﬁc interest in exhibits 31, 32, 33 and 34.
Paths. In Figure 6 we show two of the clusters identiﬁed
with HAC. We construct the visualization of a set of visitor
paths sv by computing the statistics of the longest-commonsubsequences (LCS) by comparing all sequences in the set,
and choosing the 20 most frequent ones. We visualize these
LCSs as paths by computing the shortest paths between the
exhibits in the LCSs on the mesh grid, as described previously
with respect to coordinate-based metrics (the line width is
proportional to the frequency of that LCS). One such visualization summarizes the most frequent path choices made by the
visitors in the set. Note that the visualization does not contain
time information, but only frequency, and hence frequent LCSs

do not imply that a lot of time was spent at those exhibits.
The ﬁrst cluster includes the largest group of visitors and
shows the most common behavior. HAC identiﬁed further
groups within this major cluster, for example, splitting visitors
turning right towards exhibit 6 from visitors turning left
towards exhibit 3 after exhibit 1 at the entrance. The second
cluster in Figure 6(b) shows a cluster with 10% of the visitors
who visited the exhibition space in “inverted order”, starting
from room 6. Perhaps these visitors did not understand what
was expected from them by the curators. Similarly, through
HAC we identiﬁed another group of visitors who decided to
visit room 6 ﬁrst, only to return right after back to room 1 and
continued from there, perhaps after realizing their mistake. In
general, path visualizations outlined different trends of choices,
with some individuals skipping rooms completely, with the
most common behavior consisting in following the perimeter
of the room along the outer wall.
Furthermore, we can notice that both groups make more
different choices of paths while visiting the ﬁrst rooms,
whereas the last rooms are characterized by one common path
where visitors scan the room sequentially along the outer walls.
This phenomenon was dubbed “museum shufﬂe” by the staff
of CoBrA and was associated to a decrease in attention after
around 30 minutes in the visit.
VII. D ISCUSSION AND F UTURE W ORK
The proposed solution is able to reconstruct the behavior of
a group of visitors with a pipeline of software ﬁlters. Through
a simple and inexpensive sensing infrastructure, we were able

to accurately position visitors at paintings regardless of data
loss and noise caused by our enclosures and the absence of
distance estimation from anchors.
We plan to investigate how estimating distance from anchors could impact the sensitivity of the measurement, in
particular in areas with higher density of anchors where our
technique produces more ambiguous positioning. Similarly,
we would expect substituting our enclosures with tailor-made
directional antennas to produce more robust and reliable communication ranges, and hence more accurate measurements.
With the widespread use of wearable sensors, like smart
watches, glasses, and bracelets, pervasive and ubiquitous sensing capabilities will extend further than those provided by
smart phones only. A fusion of different data sources should
allow us to better quantify the quality of the proximity relationships between visitors and artworks.
We plan to repeat our measurements in conditions of much
higher density and scale. We expect such challenging settings
to increase data loss and noise, but they also represent an
opportunity to study how positioning data can help tackling
high-density conditions, which are positioned by museum staff
at the top of their list of undesirable circumstances.

[7]

[8]

[9]

[10]

[11]

[12]

[13]

[14]

VIII. C ONCLUSIONS
We presented a method to measure person-to-object relationships via face-to-face proximity. The positionings extracted from our sensors can be processed through data mining techniques that identify group behavior. The approach is
inexpensive and requires little setup. The method provides a
reliable measurement of positioning that is not bounded to the
particular technology used to sense face-to-face proximity, and
can hence be used in a variety of scenarios and applications.
Our approach is not speciﬁc to our devices or to a particular
medium, and it applies to any technology that can map onto
the proposed binary model.
ACKNOWLEDGEMENTS
This publication was supported by the Dutch national
program COMMIT.
R EFERENCES

[15]
[16]

[17]

[18]

[19]

[20]

[21]

[1]

E. Verón and M. Levasseur, Ethnographie de l’exposition: l’espace, le
corps et le sens. Centre Georges Pompidou, Bibliothèque publique
d’information, 1989.

[22]

[2]

T. Kuﬂik, Z. Boger, and M. Zancanaro, “Analysis and prediction
of museum visitors behavioral pattern types,” in Ubiquitous Display
Environments. Springer, 2012, pp. 161–176.

[23]

[3]

M. Dobson, S. Voulgaris, and M. van Steen, “Merging ultra-low duty
cycle networks,” in Proceedings of the 41st International Conference
on Dependable Systems & Networks (DSN 2011), 2011.

[4]

C. Martella, M. Van Steen, A. Halteren, C. Conrado, and J. Li,
“Crowd textures as proximity graphs,” Communications Magazine,
IEEE, vol. 52, no. 1, 2014.

[24]

[5]

D. Lymberopoulos, J. Liu, X. Yang, R. R. Choudhury, V. Handziski,
and S. Sen, “A realistic evaluation and comparison of indoor location
technologies: experiences and lessons learned,” in Proceedings of the
14th International Conference on Information Processing in Sensor
Networks. ACM, 2015.

[25]

[6]

R. Reimann, A. Bestmann, and M. Ernst, “Locating technology for
aal applications with direction ﬁnding and distance measurement by
narrow bandwidth phase analysis,” in Evaluating AAL Systems Through
Competitive Benchmarking. Springer, 2013.

[26]
[27]
[28]

C. Beder and M. Klepal, “Fingerprinting based localisation revisited: A
rigorous approach for comparing rssi measurements coping with missed
access points and differing antenna attenuations,” in Indoor Positioning
and Indoor Navigation (IPIN), 2012 International Conference on.
IEEE, 2012.
C.-L. Li, C. Laoudias, G. Larkou, Y.-K. Tsai, D. Zeinalipour-Yazti, and
C. G. Panayiotou, “Indoor geolocation on multi-sensor smartphones,”
in Proceeding of the 11th annual international conference on Mobile
systems, applications, and services. ACM, 2013.
H. Zou, L. Xie, Q.-S. Jia, and H. Wang, “Platform and algorithm
development for a rﬁd-based indoor positioning system,” Unmanned
Systems, vol. 2, no. 03, 2014.
S. Adler, S. Schmitt, Y. Yang, Y. Zhao, and M. Kyas, “Fubloc: Accurate range-based indoor localization and tracking,” Technical report,
Microsoft Indoor Localization Competition, Tech. Rep., 2014.
A. Ashok, C. Xu, T. Vu, M. Gruteser, R. Howard, Y. Zhang, N. Mandayam, W. Yuan, and K. Dana, “Bifocus: Using radio-optical beacons
for an augmented reality search application,” in Proceeding of the 11th
annual international conference on Mobile systems, applications, and
services. ACM, 2013.
P. Lazik and A. Rowe, “Indoor pseudo-ranging of mobile devices using
ultrasonic chirps,” in Proceedings of the 10th ACM Conference on
Embedded Network Sensor Systems. ACM, 2012.
Z. Jiangy, W. Xiy, X.-Y. Li, J. Zhaoy, and J. Hany, “Hiloc: A tdoaﬁngerprint hybrid indoor localization system,” Technical report, Microsoft Indoor Localization Competition, Tech. Rep., 2014.
Y. Yoshimura, F. Girardin, J. P. Carrascal, C. Ratti, and J. Blat, “New
tools for studying visitor behaviours in museums: a case study at the
louvre,” 19th International Conference on Information Technology and
Travel & Touris, pp. 1–13, 2012.
G. Wilson, “Multimedia tour programme at tate modern,” in Museums
and the Web, vol. 3, 2004.
E. Bruns, B. Brombach, T. Zeidler, and O. Bimber, “Enabling mobile
phones to support large-scale museum guidance,” IEEE multimedia,
no. 2, pp. 16–25, 2007.
V. Kirchberg and M. Tröndle, “The museum experience: Mapping the
experience of ﬁne art,” Curator: The Museum Journal, vol. 58, no. 2,
2015.
E. Dim and T. Kuﬂik, “Automatic detection of social behavior of
museum visitor pairs,” ACM Transactions on Interactive Intelligent
Systems (TiiS), vol. 4, no. 4, p. 17, 2014.
G. Zhou, T. He, S. Krishnamurthy, and J. A. Stankovic, “Impact of radio
irregularity on wireless sensor networks,” in Proceedings of the 2nd
international conference on Mobile systems, applications, and services,
ser. MobiSys ’04, 2004.
N. Ababneh, “Radio irregularity problem in wireless sensor networks:
new experimental results,” in Proceedings of the 32nd international
conference on Sarnoff symposium, ser. SARNOFF’09, 2009.
F. Evennou, F. Marx, and E. Novakov, “Map-aided indoor mobile
positioning system using particle ﬁlter,” in Wireless Communications
and Networking Conference, 2005 IEEE. IEEE, 2005.
F. Gustafsson, F. Gunnarsson, N. Bergman, U. Forssell, J. Jansson,
R. Karlsson, and P.-J. Nordlund, “Particle ﬁlters for positioning, navigation, and tracking,” Signal Processing, IEEE Transactions on, 2002.
C. Martella, M. Dobson, A. van Halteren, and M. van Steen, “From
proximity sensing to spatio-temporal social graphs,” in Pervasive
Computing and Communications (PerCom), 2014 IEEE International
Conference on. IEEE, 2014.
M. Ester, H. P. Kriegel, J. S, and X. Xu, “A density-based algorithm
for discovering clusters in large spatial databases with noise,” in KDD,
1996.
W. E. Winkler, “String comparator metrics and enhanced decision rules
in the fellegi-sunter model of record linkage.” 1990.
J. W. Ratcliff and D. E. Metzener, “Pattern-matching-the gestalt approach,” Dr Dobbs Journal, vol. 13, no. 7, p. 46, 1988.
O. Maimon and L. Rokach, Data mining and knowledge discovery
handbook. Springer, 2005, vol. 2.
J. H. Ward Jr, “Hierarchical grouping to optimize an objective function,”
Journal of the American statistical association, vol. 58, no. 301, 1963.

