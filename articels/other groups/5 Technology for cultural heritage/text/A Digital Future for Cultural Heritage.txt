Accelerat ing t he world's research.

A Digital Future for Cultural Heritage
Carla Schroer, Michael Ashley

Related papers

Download a PDF Pack of t he best relat ed papers 

Image-Based Empirical Informat ion Acquisit ion, Scient iﬁc Reliabilit y, and Long-Term Digit al Pr…
joão barbosa
Principles and Pract ices of Robust , Phot ography-based Digit al Imaging Techniques for Museums
Michael Ashley, Mark Mudge, Carla Schroer, Tom Noble, Neffra Mat t hews
(2013) Rock Art and Digit al Technologies: t he Applicat ion of Reflect ance Transformat ion Imaging (RT I…
Mart a Díaz-Guardamino

A DIGITAL FUTURE FOR CULTURAL HERITAGE
Mark Mudgea, , Michael Ashleyb, Carla Schroer a
a
b

Cultural Heritage Imaging, San Francisco, CA, USA (info@c-h-i.org)
University of California Berkeley, CA, USA (mashley@berkeley.edu)

KEY WORDS: Cultural Heritage, Digital, Future
ABSTRACT:
The tools and standards of best practice adopted by cultural heritage (CH) professionals will determine the digital future of CH
work. This paper explores issues influencing adoption decisions and discusses emerging digital technologies encouraging
widespread adoption of digital practices. The paper explores a digital future for cultural heritage through key principles: adoption of
digital surrogates, empirical provenance, perpetual digital conservation, and the democratization of technology. The paper elucidates
digital surrogates as trusted representations of “real world” content in digital form. The paper also explains how empirical
provenance can contribute to the authenticity and reliability of digital surrogates, while perpetual digital conservation can ensure that
digital surrogates will be archived and available for future generations. The paper also investigates the emerging technologies’
potential to democratize digital technology making digital workflows easy to use for CH professionals and CH materials widely
available to diverse audiences. The paper concludes with a discussion of the implications of these fundamental principles and the
emerging technologies for the cultural heritage field.
1. INTRODUCTION
An essential element of the world's transformation through time
is surprise. The one thing the past clearly tells us about the
future is that it will contain the unexpected. The following
pages will not speculate about the future, they are limited to
what the world has taught us, particularly in the recent past, and
an assessment of where we stand today.
The tools and standards of best practice adopted by cultural
heritage (CH) professionals will determine the digital future of
cultural heritage work. We will explore issues that influence
these adoption decisions and showcase examples of emerging
digital technologies designed to remove the existing obstacles
to widespread adoption of digital practices.
Humanity's legacy can be unlocked and shared between people
through digital representations. Digital representations can
communicate elements of our CH in a variety of ways. For
clarity, we can define three types that distinguish different uses
for these representations; art and entertainment, visualization,
and digital surrogates of the world we experience.
Digital content can be fine art in its own right. It can also
entertain. This content can also be used to visualize concepts,
and illustrate hypotheses. In this case, we use the term
‘visualization’ in its broadest sense to include hearing, smell,
taste and touch. For example, a computer animation of a large
asteroid impacting the Yucatan Peninsula 65 million years ago
is helpful to visualize the cause for worldwide dinosaur
extinction. These images are useful not because they faithfully
show the shape and color of the actual asteroid moments before
impact but because they effectively communicate an idea.
Visualizations are speculative in nature to varying degrees.
Current research is exploring ways to explicitly describe the
extent of this speculation. (Hermon, S.,et al, 2006)
Digital surrogates serve a different purpose. Their goal is
reliably represent ‘real world’ content in a digital form. Their
purpose is to enable scientific study and personal enjoyment
without the need for direct physical experience of the object or

place. Their essential scientific nature distinguishes them from
speculative digital representations.They are built from intersubjectively verifiable empirical information . Digital
surrogates are the focus of this paper.
Digital surrogates of our 'real world' cultural heritage can
robustly communicate the empirical features of CH materials.
When digital surrogates are built transparently, according to
established scientific principles, authentic, reliable scientific
representations can result. These representations allow
repurposing of previously collected information and enable
collaborative distributed scholarship. Information about the
digital surrogates stored in a semantically rich 'common
language' accessible to and from locally determined archiving
architectures permit concatenation of information across many
collections and demystify complex semantic query of vast
amounts of information to efficiently find relevant material.
Digital surrogate archives remove physical barriers to scholarly
and public access and foster widespread knowledge and
enjoyment of nature and our ancestors’ achievements.
2. PRINCIPLES FOR WIDESPREAD ADOPTION OF
DIGITAL SURROGATES
Analysis of current impediments to and potential incentives for
digital surrogate adoption in CH reveals three core principles:
Empirical Provenance: For digital surrogates to find
widespread use in science and CH scholarship, easy to use,
transparent qualitative evaluation of their authenticity and
reliability by others is essential.
Perpetual Digital Conservation: The people who potentially
could use digital surrogates and acquire the empirical data used
to build them need archival conservation methods that will
guarantee their work’s availability for future generations. The
conservation plan must include capacity for contribution and
stewardship from individuals, organizations and institutions
worldwide.
Democratization of Technology: For those who study and care
for our past to do their work digitally, the means by which
robust digital information is captured and synthesized into

digital surrogates requires great simplification, cost reduction,
increased ease of use, and improved compatibility with existing
working cultures.
For the first time, recent research breakthroughs in computer
graphics, robotics, and machine vision have converged to make
a new generation of robust digital tools for construction of
digital surrogates possible. Adaptation of these breakthroughs
to the requirements of the CH community is underway. This
work is explored in Section 5.
For widespread cultural heritage adoption of digital surrogates
to occur, the CH workers who build and use digital surrogates
must be able to employ these new tools themselves. The
existing digital technology model where a separate class of
technology savvy digital documentation ‘providers’ service the
documentary needs of professional CH ‘consumers’ has proven
expensive, cumbersome, unproductive and unpopular. In the
following pages, we will examine how new approaches can
simplify digital surrogate workflows and promote their
adoption.
Widespread endorsement of the principles of empirical
provenance, perpetual digital conservation, and democratization
of technology can guide decisions regarding which tools and
methods are adopted. Implementation of new working practices
based on these principles can provide the necessary preconditions to realize a fourth principle with far-reaching
advantages:
Tolerance of diversity – So long as the principles of empirical
provenance, perpetual digital conservation, and democratization
of Technology are followed, particular information acquisition
and management practice variations due to local conditions or
the nature of the examined field can be tolerated.
Considered along with the powerful dynamic of change
attached to all things digital and the history of human nature’s
resistance to conformity, adoption of digital surrogate-based
workflows will be encouraged by permitting decentralized
optimization of digital information architectures. The scholarly,
discipline-based, evolving standards of best practice will
continue to guide local practice as it always has. Worldwide
access to, evaluation, and oversight of these practices, aided by
semantic query enabled access to the empirical provenance of
digital surrogates and by use of perpetual digital conservation
practices for digital surrogates along with their source data, can
allow the proven, self-corrective mechanisms of the scientific
method to do their work.
The advantages presented by adoption of digital surrogates are
great, but can only be attained if well recognized obstacles are
overcome and the related incentives realized. As discussed
below, the fundamental means to enable adoption of digital
surrogates are understood and the necessity to produce them is
now driving the ongoing development of new tools, methods,
and standards. The following three sections examine these
principles to aid digital surrogate adoption and offer a roadmap
for hope.
3. EMPIRICAL PROVENANCE
A fundamental problem of the digital age is the qualitative
assessment of digital surrogate reliability during scientific
inquiry. A solution to this problem is necessary for there to be a
digital future for cultural heritage.

Widespread adoption of digital surrogates by science in all
fields, including the multi-disciplinary study of our cultural
heritage, requires confidence that the data they represent is
reliable. For a scholar to use a digital surrogate, built by
someone else, in their own work, they need to know that what’s
represented in the digital surrogate is what’s observed on the
physical original. If archaeologists are relying on virtual 3D
models to study Paleolithic stone tools, they must be able to
judge the likelihood that a feature on the model will also be on
the original and vice versa. If they can’t trust that it’s an
authentic representation, they won’t use the digital surrogate in
their work.
We suggest that the concept of ‘empirical provenance’ offers to
advance our understanding of the role of digital surrogates in
scientific inquiry, enhance the development of techniques to
digitally represent our world, and increase the adoption of
digital surrogates as source material both for scientific research
in general and the study of our collective cultural heritage in
particular.
An essential element of traditional scientific inquiry is the
systematic gathering of observations about the world through
the senses. In the very, very old and still vigorously pursued
epistemological discussion about the nature of human
knowledge, the observations of the senses are labeled
‘empirical’
Within scientific discourse the methodology employed in the
process of generating scientific information has been
traditionally called the inquiry’s ‘provenance’. This provenance
is carefully recorded in lab notebooks or similar records during
the inquiry and then becomes an integral element of the
published results. This provenance explains where the
information came from and permits replication experiments,
central to scientific practice, to confirm the information’s
quality. Such provenance may include descriptions of
equipment employed, mathematical and logical operations
applied, controls, oversight operations, and any other process
elements necessary to make both the inquiry and its results clear
and transparent to scientific colleagues and the interested
public.
Widespread adoption of digital surrogates requires that they be
able to pass this traditional lab notebook test. Empirical
provenance is for digital surrogates the equivalent of what a lab
notebook is for non-digital representations. Empirical
provenance is the extension of classic scientific method into
digital documentary practices used to build digital surrogates.
Empirical provenance records the journey of original, unaltered
empirical evidence from its initial data capture all the way
through the image generation process pipeline to its final form
as a digital surrogate. Just as ‘real-world’ cultural material
requires a provenance identifying what it is, establishing its
ownership history, and proving its authenticity, digital
surrogates require an empirical provenance, to document the
imaging practices employed to create them. Empirical
provenance ensures access to both original empirical data,
original photographs for example, and the complete process
history enabling the user to generate a confirmatory
representation to evaluate the quality and authenticity of the
data. That way, the user can decide for themselves whether to
rely on the digital surrogate, or not. Empirical provenance

permits the assessment of digital surrogate accuracy. The
experience of those engaged in distributed, Internet-based
scientific inquiry confirms the necessity of documenting how
digitally represented information is generated. These
collaborations, frequently found in the biological sciences, rely
heavily on process accounts of digital data creation to assess the
quality of information contributed by the cooperating partners
and make their own work valuable to others (Zhao, J., et al,
2003).
The attributes of empirical provenance information for a given
digital surrogate are dependent on the tools and methods
employed to build it. For a digital photograph, the empirical
provenance information would include XMP data such as: the
camera make and model, firmware version, shutter speed, and
aperture; parameters used to convert the raw sensor data into an
image like color temperature; and all editing operations
performed in tools like Photoshop such as cropping, re-sizing,
distortion correction, sharpening, etc. These editing operations
can have a profound impact on image reliability and are
examined in greater detail below. For a 3D geometric model
displaying photo-realistic surface texture and reflective material
properties, the empirical provenance is complex. For these
digital surrogates, complete process history accounts are
required for the alignment of shape data acquired from different
viewpoints, the registration of textural image data to geometry,
the correction of geometric acquisition errors such as voids,
smoothing in low signal to noise ratio situations, the effects of
compressive data reduction, and other issues raised by the
selected imaging method. In each case, whether digital photo or
3D model, the attributes including quantity of records, and ease,
difficulty, or even possibility of empirical provenance
collection result from the practices used to build the digital
surrogate.
Only practices able to provide a complete empirical provenance
can be used to construct reliable digital surrogates. Practices
unable to produce a complete empirical provenance cannot be
used to create reliable digital surrogates since their digital
artifacts cannot be subjected to rigorous qualitative evaluation.
The requirement for empirical provenance information informs
digital technology development and adoption. Tools and
methods used to build digital surrogates that feature
simplification and trivially configurable automation of
empirical data post processing, including empirical provenance
generation, present significant benefits over those that call for
significant amounts of subjective judgments by a skilled
operator, since every operator action that transforms empirical
content must be documented in a digital log for future scientific
evaluation.
The importance of automation in the construction of reliable
digital surrogates is highlighted by a recent major study (Berns,
R.S., et al, 2005). This study examined the digital imaging
practices in leading US museums and libraries. The study states,
“Most museums included some visual editing and other forms
of image processing in their workflows…When investigated
closely, it was found that visual editing decreased color
accuracy in all cases… In addition to visual editing, many
images also incurred retouching and sharpening steps. The fact
that many of the participants sharpened the images either at
capture or before the digital master was saved raised the
question of whether the implications of the choices made were
well understood. Most of the image processing carried out was

not automated; automation represents a possibility for
improvement in setting up consistent, reproducible workflows.”
While an artist’s touch can increase the sales of a print in a
museum gift shop or create a stunning cinematic effect, it has
little direct role in the scientific construction of digital
surrogates. The development of many of today’s digital
imaging tools was driven by the entertainment industry’s desire
to create special effects for movies and television, computer
animations, video games, and multimedia products. Unlike the
entertainment business where a good-looking image is the goal,
scientific documentation requires that the material be
represented reliably. If the empirical provenance, enabling
assessment of reliability, is lacking, the digital representation
may be enjoyed for visualization or entertainment purposes but
not used as a digital surrogate.
As well as reliability, the synergistic combination of empirical
provenance and automated digital processing, requiring trivial
operator configuration, offer advantages for the organization,
communication and preservation of digital knowledge. Once the
process used to construct a digital surrogate is automated, an
empirical provenance log describing the process can be
automatically produced. In turn, once the types of process
history actions entered into this log are determined, they can be
mapped in software by a trained specialist to semantically
robust information architectures. Once this software mapping
process has been completed, digital processing can
automatically record empirical provenance information into
these selected semantic information management architectures
as the digital surrogates are ’born’.
An example of a robust semantic common language is offered
by the International Council of Museums. A working group of
ICOM’s Committee on Documentation (CIDOC) is now in the
process of mapping Empirical Provenance structures into their
Conceptual Reference Model (CRM), ISO standard 21127.
4. PERPETUAL DIGITAL CONSERVATION
"Time and accident are committing daily havoc on the originals
deposited in our public offices. … The lost cannot be
recovered; but let us save what remains; not by vaults and locks
which fence them from the public eye and use, in consigning
them to the waste of time, but by such a multiplication of
copies, as shall place them beyond the reach of accident." Thomas Jefferson to Ebenezer Hazard, February 18, 1791.
(Smith, A., 2001)
We advocate for both individual professional responsibility and
multi-institutional, multi-disciplinary curatorial management of
digital heritage content for the foreseeable future. Unlike the
physical archives of the Library of Alexandria, lost forever to
humanity, digital heritage can be in more than one place at a
time and in more than one form, potentially assuring its
longevity despite the ephemeral nature of the media. This
multiplicity of location and form is both the promise and the
peril of digital heritage.
With increasingly diverse data formats, larger file sizes,
changing media types, distributed databases, networked
information and transitive metadata standards, how are today’s
heritage specialists to plan for such an uncertain virtual future?
It is increasingly difficult for individual scholars and
researchers to do the right thing when it comes to digital
heritage conservation. The accountability for the conservation

of digital heritage falls to all in the CH field, but what is a
reasonable course of action in the face of such adversity.

(DRM) or archaic security protocols severely limit the longterm viability of digital content.

The importance of developing sensible plans to preserve our
digital heritage cannot be minimized. Responsible preservation
of our most valued digital data requires answers to key
questions: Which data should we keep and how should we keep
it? By digital heritage conservation, we mean the decisionmaking criteria to discern what must be saved from what can be
lost. Everything can't be saved nor is it desirable to do so. How
is this data to be saved to ensure access in five years, 100 years
or 1,000 years? In the next 100 years, we will go through
dozens of generations of computers and storage media, and our
digital data will need to be transferred from one generation to
the next, by someone we trust to do it. Finally, who will pay for
all this?

Furthermore, the Archaeology Data Service (ADS) in the UK
defines the most critical factor for digital heritage sustainability
is to “plan for its re-use.” (ADS web 2007). Indeed, the design
of decision making principles for digital heritage conservation
should above all aim to the perpetual use and re-use of this
content by striving to assure its reliability, authenticity and
usability throughout the archival lifecycle.

We produce more content now than it is humanly possible to
preserve. Current estimates are that in 2006, 161 billion trillion
bytes -- 161 exabytes, or 161 billion gigabytes -- of digital data
were generated in the world -- equivalent to 12 stacks of books
reaching from the Earth to the sun. In just 15 minutes, the world
produces an amount of data equal to all the information held at
the Library of Congress. (Barksdale, J. and Berman, F. 2007)
We can think of digital heritage in terms of what the value is of
what is being saved, its viability, how available it is to
stakeholders, and how long it will last. In other words, an ideal
digital heritage repository would conserve archival quality
digital surrogate files in an openly accessible way, forever. This
is the simplest definition of a trusted repository.
The Library of Congress devised a set of sustainability factors
for digital content that are as pragmatic as they are difficult to
maintain over time. The core principles we advocate in this
paper strongly adhere to these sustainability factors. (LC.,
2004)
Adoption: Wide adoption of a given digital format makes it
less likely to become obsolete while reducing investment by
archival institutions for its migration or emulation.
Transparency: Open to direct analysis without interpretation,
transparency is characterized by self-evidence and substantive
metadata. Those who use digital surrogates benefit from
complete and accessible empirical provenance.
Self-documentation: XMP (Extended Metadata Platform) and
other key forms of self-evidence, such as automatically
generated empirical provenance data, dramatically increase the
chances for a digital object to be sustainable over time.
External dependencies: The less a media form is dependent on
proprietary software/hardware, the better. If two documentation
methodologies can yield similar results in terms of accuracy
and productivity, the more open / less externally dependent
method is recommended.
Impact of patents and copyrights: Intellectual property
limitations bound to content can inhibit its archival capabilities
in profound ways. Whenever possible, unambiguous, open
licensing for content is recommended.
Technical protection mechanisms: “No digital format that is
inextricably bound to a particular physical carrier is suitable as
a format for long-term preservation; nor is an implementation of
a digital format that constrains use to a particular device or
prevents the establishment of backup procedures and disaster
recovery operations expected of a trusted repository.”
Additionally, limitations imposed by digital rights management

Digital technology and the creation of ‘born digital’ content are
indispensable aspects of cultural heritage management today.
From low-tech documentation like Microsoft Office, html
websites, PDF, and photography, to more complex technologies
such as panoramas, object movies, laser/lidar scanning,
scanning electron microscopy (SEM), x-ray fluorescence
(XRF), Global Positioning System (GPS), 3D modelling, and
distributed databases, to cutting edge techniques including Web
2.0, reflection transformation imaging (RTI), algorithmic
generation of drawings from surface normals, and the family of
photogrammetry influenced texture and 3D geometry
acquisition tools, these new media types form a spectrum of
opportunities and challenges to the preservation field that did
not exist even 30 years ago.
We are at a unique point in history, where cultural heritage
professionals must work to care for the physical past while
assuring that there will be a digital record for the future. Peter
Brantley, Executive Director of the Digital Library Foundation,
thinks, “The problem of digital preservation is not one for
future librarians, but for future archaeologists.” If one imagines
that the well-intentioned efforts of researchers and scholars in
the modern era could be unreadable only fifty years from now,
there is tremendous responsibility on individual CH
professionals to insure a future for their digital work.
As explored in Section 2, in the mid 1990’s, a critical gap
between those who provide information for conservation
(providers) through construction of digital heritage
documentation and those who use it (consumers) was identified
by the International Council of Monuments and Sites
(ICOMOS), the Getty Conservation Institute (GCI) and the
International Committee for Architectural Photogrammetry
(CIPA), who together formed RecorDIM (for Heritage
Recording, Documentation and Information Management)
Initiative Partnership (Getty Trust 2005).
A 2006, GCI-led literature review demonstrates that most of the
key needs identified in RecorDIM are evidently still with us.
After reviewing the last 20 years of cultural heritage
documentation, the authors concluded, “only 1/6th of the
reviewed literature is strongly relevant to conservation.”
(Eppich,R., Chabbi, A., 2006) Their suggested remedy is to
correlate the needs of conservation with the potential
documentation technologies by involving more diverse
audiences and by creating active partnerships between heritage
conservationists, heritage users, and documentation specialists.
We are focusing on another gap, between cultural heritage and
digital heritage, that has been created as we have shifted away
from paper in favor of pixels throughout all of our
communication and analytic processes globally. In 2000, the
Library of Congress recognized that “never has access to
information that is authentic, reliable and complete been more
important, and never has the capacity of libraries and other

heritage institutions to guarantee that access been in greater
jeopardy.” (LC, 2002)
We see the crisis not between producers and consumers of
digital data, but in the capacities of cultural heritage specialists
to produce the content for themselves in ways that can adhere to
the principles defined by the LOC and other key international
standards bodies. There is a desperate need for methodologies
for digital heritage conservation that are manageable and
reasonable, and most importantly, can be enacted by cultural
heritage professionals as essential elements of their daily work.
The collaboration between cultural heritage professionals and
digital specialists should lead to the democratization of
technology through its widespread adoption, not the continued
mystification of technology that is still being defined by the
persistence of a producer/consumer model (Tringham/Ashley).
5. DEMOCRATIZATION OF TECHNOLOGY
The evaluation of emerging technologies presented here is
completely pragmatic. We will describe some of the many tools
that can remove the impediments to and promote adoption of
digital surrogates in CH work.
Recent work has shown that computational extraction of
information from digital photographs can create digital
surrogates that reliably describe the 2D and 3D shape, location,
material, and reflection properties of our world. Among these
new technologies are single and multi-view reflection
transformation imaging, the algorithmic extraction of surface
feature drawings from reflection information, as well as
photogrammetric breakthroughs that permit automatically
calibrated and post-processed textured 3D geometric digital
surrogates of objects and sites. We will explore these
developments in detail later in this section.
The emergence of the new family of robust digital documentary
tools offering automatic post-acquisition processing overcomes
an important barrier to the adoption of digital workflows. As
was discussed in Section 3, automation requiring trivial
configuration offers enhanced reliability and greatly reduces the
computer technology expertise necessary to manage a digital
workflow. These methods leverage new knowledge to enable
CH professionals to build digital surrogates with a minimum of
additional training. In turn, this automation frees CH workers to
concentrate on the CH tasks before them.
Digital photography skills are already widespread and
disseminating rapidly. Employing digital photography to
provide the empirical data for digital surrogates also lowers
financial barriers to digital adoption. As will be seen below,
rich 2D and 3D information can be captured with the equipment
found in a modern wedding photographer’s kit
Reflection Transformation Imaging (RTI), invented by Tom
Malzbender of Hewlett-Packard Laboratories (HP Labs), is an
example of computational extraction of 3D information from a
sequence of digital photographs. RTI data acquisition analyzes
reflections from a subject’s surface. When a surface is
photographed from a fixed position and illuminated from
different known locations, the surface’s properties of shape and
many material attributes, including color, can be
computationally revealed. Reflections disclose shape by
capturing the directional vector, mathematically named a
‘normal’ that is perpendicular to the surface at the
photographically sampled location. Knowledge of surface

normals permits construction of the surface’s 3D geometry as in
the process of photometric stereo or codification of the normal
information on a per-pixel-basis in a 2D image as in polynomial
texture mapping (PTM) (Malzbender, T., et al, 2001).
3D lighting models use this normal information to permit
relighting of the subject from any direction and with any
illumination source in interactive viewing software. The normal
information can also be mathematically enhanced to disclose
surface features that are difficult or impossible to see, even
under direct physical examination (Mudge, M., et al, 2005).
RTI has been widely used in law enforcement, natural science,
and cultural heritage
Automatic acquisition and post-processing using photometric
stereo in combination with RTI has been demonstrated to
effectively document cuneiform inscriptions from the collection
of the Katholieke Universiteit Leuven (KUL) (Willems, G., et
al, 2005)
Two projects—one involving teams from the University of
Southern California (USC) and the University of Illinois,
Urbana-Champaign, and the other a partnership between USC
and the Oriental Institute of the University of Chicago—are
extensively using RTI in combination with PTMs to document
dozens of cylinder seals and thousands of cuneiform tablets
from ancient Mesopotamia and Persia. These projects use fixed
light position dome capture apparatus modelled after similar
equipment designed by HP Labs and Cultural Heritage Imaging
(CHI) (Mudge, M., et al, 2006) (Malzbender, T., et al, 2001)
and automatic scripts developed by CHI to generate the finished
RTIs. The scripts create a log file of all operations performed.
Combined with information stored in Adobe software .XMP
files generated during conversion of the original RAW digital
images, all empirical provenance for the RTIs is recorded. The
Institute for Information Science and Technology (ISTI) of the
Italian National Research Council has used RTI to document
bas-relief sculpture and architectural details. This technique
employs site-specific, algorithmically generated templates to
determine illumination locations. Their work has also
demonstrated the effects of light position sample quantities and
spatial distribution upon the accuracy of captured normal
information (Dellepiane, M., et al, 2006).
RTI’s can also be acquired using a method developed by a
collaboration between CHI and HP Labs called Highlight RTI
(HRTI). (Mudge, M., et al, 2006) HRTI includes one or two
shiny black spheres in each image of the photographic
sequence. The light source location is recorded on the sphere(s)
as a highlight, or bright spot, on the sphere’s surface. This
highlight indicates the directional vector pointing to the
illumination location. HRTI permits determination of
illumination location after the image acquisition session and
offers several additional advantages: it permits a broad subject
scale range, from 1-2 cm in diameter to several meters;
pragmatic selection of light direction sampling locations, which
is helpful in avoiding environmental obstructions, especially
during field work; and the use of a simple, low-cost
photographic equipment kit. HRTI has been used to document:
Magdalenian petroglyphs at the Paleolithic Petroglyphs of the
Côa Valley UNESCO site in Portugal by the Côa Valley
Archaeological Park, the Centro Nacional de Arte Rupestre, the
Universidade do Minho (Minho) and CHI. (Mudge, M., et al,
2006) Software that automatically identifies black ball
highlights is being developed by a collaboration between
Minho, HP Labs and CHI.

Traditional work practice in many CH disciplines use drawings
as a medium for dissemination and interpretive discourse. Nonphoto-realistic rendering (NPR) research by Szymon
Rusinkiewicz and others is using surface normal information to
enable the algorithmic generation of drawings. These drawings
use both photographically captured color and 3D surface shape
data to enable a broad range of user selected drawing styles to
represent desired surface features. These information rich
graphic representations integrate the power of digital imaging
with proven, widely used, and familiar modes of CH
professional activity.
Recent developments in photogrammetric technologies can
generate 3D textured geometric digital surrogates of objects and
sites from automatically calibrated and post-processed
sequences of digital photographs. The European Project for
Open Cultural Heritage (EPOCH), a seven year European
Union sponsored initiative to develop digital tools for CH,
fostered a major advance in photogrammetry-based 3D imaging
using uncalibrated digital photos. The EPOCH 3D Webservice,
developed by the computer vision group at KUL allows
archaeologists and engineers to upload digital images to servers
where they perform an automatic 3D reconstruction of the scene
and return the textured 3D geometry back to the user (EPOCH
web, 2007). The ISTI research group has created a loader for
this 3D content into their own EPOCH open source tool
MeshLab (MeshLab web, 2007). MeshLab provides a set of
tools for editing, cleaning, healing, inspecting, rendering and
converting 3D polygonal textured geometry. MeshLab can
create an automatic log of all operations it performs on 3D
content, generating an empirical provenance record.
Commercial software, initially developed for the aerial mapping
and mining industries by Adamtech, an Australian company,
can automatically calibrate digital photo sequences from one or
more cameras, automatically generate dense textured 3D
polygonal geometry from one or more image pairs, and
automatically align this 3D content using photogrammetric
bundle adjustment (Adam web). These tools have been used by
U.S. Bureau of Land Management researchers Neffra Mathews
and Tom Noble to document Native American petroglyphs at
Legend Rock Wyoming State Park in collaboration with the
Wyoming State Parks, Wyoming State University and CHI.
Photogrammetry digital image sequences were captured tandem
with CHI’s RTI photo sequence. The integrated photo
sequences demonstrate the synergies between automated
photogrammetric capture of range-based geometry and
reflection-based capture of normal data. These synergies,
presented at the Computer Applications in Archaeology
conference in Berlin, April 2007 include co-registered RTI
images free of optical distortions, algorithmically generated
NPR drawings, and dense, textured 3D geometry. CHI
submitted the same image sequence of a bas-relief sculpted
architectural feature to test the 3D geometry produced by
Adamtech software against that returned from the EPOCH 3D
Webservice. The results showed dense 3D geometrical
information of equivalent quality.
6. CONCLUSIONS
The principles of empirical provenance, perpetual digital
conservation, democratization of technology, and tolerance of
diversity provide a digital future for cultural heritage. Informed
by these principles, emerging tools and methods will enable CH
professionals to build reliable, reusable, archive friendly, digital

surrogates by themselves. Archives of digital surrogates can
enable distributed scholarship and public access. The aesthetic
quality, usefulness to convey ideas, and completeness of
empirical provenance information can guide decisions
regarding which digital representations are perpetually
conserved.
7. REFERENCES
ADAM web. ADAM Technology website.
http://www.adamtech.com.au (accessed 8 June 2007)
ADS web Archaeological Data Service Website (accessed June
2007) http://ads.ahds.ac.uk/project/faq.html
Barksdale, J. and Berman, F. 2007. Saving Our Digital
Heritage,.
http://www.washingtonpost.com/wpdyn/content/article/2007/05/15/AR2007051501873.html
(accessed 4 June, 2007)
Berns, R.S., Frey, F.S., Rosen, M.R., Smoyer, E.P.M., Taplin,
L.A. 2005. Direct Digital Capture of Cultural Heritage
Benchmarking American Museum Practices and Defining
Future Needs - Project Report, MCSL Technical Report.
Dellepiane, M., Corsini, M., Callieri, M., Scopigno, R., 2006
High Quality PTM Acquisition: Reflection Transformation
Imaging for Large Objects, Proceedings of the7th International
Symposium on Virtual Reality, Archaeology and Cultural
Heritage (VAST2006), Eurographics Association, pg 179-186
EPOCH web, EPOCH Webservice (accessed April 2007)
http://homes.esat.kuleuven.be/~visit3d/webservice/html/
Eppich, R., Chabbi, A., 2006 How Does Hi-tech Touch the
Past? Does It Meet Conservation Needs? Results from a
Literature Review of Documentation for Cultural Heritage, The
e-volution of Information Communication Technology in
Cultural Heritage Epoch Publication, pg 94-99
Getty Trust, 2005., About RecorDIM, (accessed 4 June, 2007)
http://extranet.getty.edu/gci/recordim/about.html
Hermon, S. Nikodem, J., Perlingieri, C., 2006 Deconstructing
theVR – Data Transparency, Quantified Uncertainty and
Reliability of 3D Models, Proceedings of the7th International
Symposium on Virtual Reality, Archaeology and Cultural
Heritage (VAST2006), pg 123-129
LC, 2002 Preserving Our Digital Heritage: Plan for the
National Digital Information Infrastructure and Preservation
Program. Council on Library and Information Resources
(CLIR) and the Library of Congress, Washington, D.C. LC.,
2004., Sustainability of Digital Formats, Washington, D.C.,
http://www.digitalpreservation.gov/formats/intro/intro.shtml
(accessed 4 June, 2007)
LC., 2004., Sustainability of Digital Formats, Washington,
D.C.,http://www.digitalpreservation.gov/formats/intro/intro.sht
ml (accessed 4 June, 2007)
Malzbender, T., Gelb, D., and Wolters, H. 2001. Polynomial
Texture Maps. Proceedings of ACM Siggraph 2001

MeshLab web, MeshLab website (accessed May 2007),
http://meshlab.sourceforge.net
Mudge, M., Voutaz J.P., Schroer C., Lum M., 2005. Reflection
Transformation Imaging and Virtual Representations of Coins
from the Hospice of the Grand St. Bernard, Proceedings of 6th
International Symposium on Virtual Reality, Archaeology and
Cultural Heritage (VAST2005), Eurographics Association, pp.
29– 39.
Mudge, M., Malzbender, T., Schroer , C., Lum, M., 2006 New
Reflection Transformation Imaging Methods for Rock Art and
Multiple-Viewpoint Display, Proceedings of the7th
International Symposium on Virtual Reality, Archaeology and
Cultural Heritage (VAST2006), Eurographics Association, pg
195-200
Smith, A., 2001. The Evidence in Hand: Report on the Task
Force on the Artifact in the Library Collections, Washington,
D.C.
http://www.clir.org/pubs/reports/pub103/contents.html
(accessed 4 June, 2007)
Smith, A., 2006. Academic Amnesia: Who Is Preserving Our
Data?,
Berkeley,
CA.
(accessed 4 June,
2007)
http://cshe.berkeley.edu/events/index.php?id=208
Tringham, R., Ashley Lopez, M., 2001, The Democratization of
Technology, Virtual Systems and Multimedia Proceedings 7th
International Conference on
Willems, G., Verbiest, F., Moreau, W. Hameeuw, H., Van
Lerberghe, K., Van Gool, L., 2005. Easy and cost-effective
cuneiform digitizing. In: Proceeedings of the 6th International
Symposium on Virtual Reality, Archaeology, and Intelligent
Cultural Heritage, Pisa, Italy, pp. 73-80.
Zhao J., Goble C., Greenwood M., Wroe C., Stevens R., 2003.
Annotating, linking, and browsing provenance logs for escience. Proceedings of the Workshop on Semantic Web
Technologies for Searching and Retrieving Scientific Data,
October 2003.

