{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "# import train_test_split \n",
    "from sklearn.model_selection import train_test_split\n",
    "from os import listdir\n",
    "from methods import ARTICLES_DIR,remove_stop_words\n",
    "from typing import List,Dict\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    " 1. load all the documents\n",
    " 2. vectorize each document, 1 for word existing in the document, 0 for not existing\n",
    " 3. cluster the documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "לטעון את כל המסמכים\n",
    "\n",
    "להפריד כל מסמך לפי רווח רגיל\n",
    "\n",
    "לעשות אוסף של המילים\n",
    "\n",
    "ולעבור כל מסמך ומסמך, האם מילה קיימת או לא.\n",
    "\n",
    "בלי stemming ובלי הורדת מילות טפל"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: change the directories and remove files to get to 50 total articles.\n",
    "paths=[ARTICLES_DIR,\n",
    "       f\"{ARTICLES_DIR}/other groups/5 Technology for cultural heritage/text\",\n",
    "       f\"{ARTICLES_DIR}/other groups/12 Visitors guide archeological sites/text files\",\n",
    "       f\"{ARTICLES_DIR}/other groups/14 Information presentation museum/txt\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# כתוב פונקציה שמקבלת מחרוזת, מחזירה מערך של מחרוזות של המילים במחרוזת המסופקת\n",
    "# מוסיפה את הרשימה שחוזרת לתוך אובייקט מסוג set\n",
    "\n",
    "def split_str(document:str)->List[str]:\n",
    "    return document.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic:Dict[int,Dict[str,bool]]={}\n",
    "set_of_words=set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading file ./articels other groups\n",
      "Error reading file ./articels/other groups/5 Technology for cultural heritage/text pdftotext3.zip\n"
     ]
    }
   ],
   "source": [
    "for path in paths:\n",
    "    arts=listdir(path)\n",
    "    for art in arts:\n",
    "        if art=='.DS_Store': continue\n",
    "        try:\n",
    "            with open(f\"{path}/{art}\",'r',encoding=\"UTF-8\") as file:\n",
    "                set_of_words.update(split_str(file.read()))\n",
    "        except:\n",
    "            print(\"Error reading file\",path,art)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stop_words_english.txt','r',encoding=\"UTF-8\") as file:\n",
    "    stop_words=set(file.read().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_of_stop_words=set(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(set_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(set_of_words-set_of_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_of_words-=set_of_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set_of_words)\n",
    "dic.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading file ./articels other groups\n",
      "Error reading file ./articels/other groups/5 Technology for cultural heritage/text pdftotext3.zip\n"
     ]
    }
   ],
   "source": [
    "# dic:Dict[int,Dict[str,bool]]={}\n",
    "id=1\n",
    "for path in paths:\n",
    "    arts=listdir(path)\n",
    "    for art in arts:\n",
    "        if art=='.DS_Store': continue\n",
    "        try:\n",
    "            with open(f\"{path}/{art}\",'r',encoding=\"UTF-8\") as file:\n",
    "                temp:Dict[str,bool]={}\n",
    "                content=set(remove_stop_words(file.read()).split())\n",
    "                \n",
    "                # content=remove_stop_words(file.read())\n",
    "                for word in set_of_words:\n",
    "                    temp[word]=1 if word in content else 0\n",
    "                    # temp[word]=content.count(word)\n",
    "                dic[id]=temp\n",
    "                id+=1\n",
    "        except:\n",
    "            print(\"Error reading file\",path,art)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199, 198)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id,len(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame.from_dict(dic,orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198, 149856)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df),len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category\"]=df.index.map(lambda x: int(x//50)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"df after category - model vectors for classification.pcl\",\"wb+\") as file:\n",
    "    dump(df,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"df after category - model vectors for classification.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df : collection of vectors\n",
    "X=df.drop([\"category\"],axis=1)\n",
    "y=df[\"category\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X, y, test_size=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9b025add082eba9f465bb7a51d61eaafbf35b7a16776511b49a7c1679204e3ae"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
