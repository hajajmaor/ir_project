{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import train_test_split \n",
    "from sklearn.model_selection import train_test_split\n",
    "from os import listdir\n",
    "from methods import ARTICLES_DIR,remove_stop_words\n",
    "from typing import List,Dict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    " 1. load all the documents\n",
    " 2. vectorize each document, 1 for word existing in the document, 0 for not existing\n",
    " 3. cluster the documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "לטעון את כל המסמכים\n",
    "\n",
    "להפריד כל מסמך לפי רווח רגיל\n",
    "\n",
    "לעשות אוסף של המילים\n",
    "\n",
    "ולעבור כל מסמך ומסמך, האם מילה קיימת או לא.\n",
    "\n",
    "בלי stemming ובלי הורדת מילות טפל"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: change the directories and remove files to get to 50 total articles.\n",
    "\n",
    "paths=[(ARTICLES_DIR,50),\n",
    "       (f\"{ARTICLES_DIR}/other groups/5 Technology for cultural heritage/text\",18),\n",
    "       (f\"{ARTICLES_DIR}/other groups/12 Visitors guide archeological sites/text files\",19),\n",
    "       (f\"{ARTICLES_DIR}/other groups/14 Information presentation museum/txt\",18)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "52\n",
      "51\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "for path,_ in paths:\n",
    "    path=f\"../{path}\"\n",
    "    print(len(listdir(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# כתוב פונקציה שמקבלת מחרוזת, מחזירה מערך של מחרוזות של המילים במחרוזת המסופקת\n",
    "# מוסיפה את הרשימה שחוזרת לתוך אובייקט מסוג set\n",
    "\n",
    "def split_str(document:str)->List[str]:\n",
    "    return document.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic:Dict[int,Dict[str,bool]]={}\n",
    "set_of_words=set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading file .././articels other groups\n",
      ".././articels 48\n",
      ".././articels/other groups/5 Technology for cultural heritage/text 65\n",
      ".././articels/other groups/12 Visitors guide archeological sites/text files 83\n",
      ".././articels/other groups/14 Information presentation museum/txt 100\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "# בניית מילון המונחים\n",
    "for path,count in paths:\n",
    "    path=f\"../{path}\"\n",
    "    arts=listdir(path)\n",
    "    for i in range(count):\n",
    "        art=arts[i]\n",
    "        if art=='.DS_Store': continue\n",
    "        try:\n",
    "            with open(f\"{path}/{art}\",'r',encoding=\"UTF-8\") as file:\n",
    "                set_of_words.update(split_str(file.read()))\n",
    "            counter+=1\n",
    "            \n",
    "        except:\n",
    "            print(\"Error reading file\",path,art)\n",
    "            i-=1\n",
    "    print(path,counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../stop_words_english.txt','r',encoding=\"UTF-8\") as file:\n",
    "    stop_words=set(file.read().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_of_stop_words=set(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_of_words-=set_of_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set_of_words)\n",
    "dic.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading file .././articels other groups\n"
     ]
    }
   ],
   "source": [
    "# dic:Dict[int,Dict[str,bool]]={}\n",
    "id=1\n",
    "for path,count in paths:\n",
    "    path=f\"../{path}\"\n",
    "    arts=listdir(path)\n",
    "    for i in range(count):\n",
    "        art=arts[i]\n",
    "        if art=='.DS_Store': continue\n",
    "        try:\n",
    "            with open(f\"{path}/{art}\",'r',encoding=\"UTF-8\") as file:\n",
    "                temp:Dict[str,bool]={}\n",
    "                content=set(remove_stop_words(file.read()).split())\n",
    "                \n",
    "                # content=remove_stop_words(file.read())\n",
    "                for word in set_of_words:\n",
    "                    temp[word]=1 if word in content else 0\n",
    "                    # temp[word]=content.count(word)\n",
    "                dic[id]=temp\n",
    "                id+=1\n",
    "        except:\n",
    "            print(\"Error reading file\",path,art)\n",
    "            i-=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id,len(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame.from_dict(dic,orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 78977)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df),len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category\"]=df.index.map(lambda x: 1 if int(x//49)==0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"df after category - model vectors for classification.pcl\",\"wb+\") as file:\n",
    "    dump(df,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"df after category - model vectors for classification.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    52\n",
       "1    48\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df[\"category\"].value_counts()\n",
    "# df.drop(columns=[\"category\"],inplace=True)\n",
    "#צריכים לראות 50-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df : collection of vectors\n",
    "X=df.drop([\"category\"],axis=1)\n",
    "y=df[\"category\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X, y, test_size=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# אימון classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logistic_regression=LogisticRegression()\n",
    "model_logistic_regression.fit(X_train,y_train)\n",
    "logistic_regression_pred=model_logistic_regression.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89         5\n",
      "           1       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.90        10\n",
      "   macro avg       0.92      0.90      0.90        10\n",
      "weighted avg       0.92      0.90      0.90        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,logistic_regression_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_naive_bayes=GaussianNB()\n",
    "model_naive_bayes.fit(X_train,y_train)\n",
    "naive_bayes_pred=model_naive_bayes.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.77         5\n",
      "           1       1.00      0.40      0.57         5\n",
      "\n",
      "    accuracy                           0.70        10\n",
      "   macro avg       0.81      0.70      0.67        10\n",
      "weighted avg       0.81      0.70      0.67        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,naive_bayes_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_k_neighbors_classifier=KNeighborsClassifier(2,weights='distance',algorithm='auto')\n",
    "model_k_neighbors_classifier.fit(X_train,y_train)\n",
    "k_neighbors_classifier_pred=model_k_neighbors_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         5\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.50        10\n",
      "   macro avg       0.25      0.50      0.33        10\n",
      "weighted avg       0.25      0.50      0.33        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,k_neighbors_classifier_pred,zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_random_forest=RandomForestClassifier(n_estimators=250)\n",
    "model_random_forest.fit(X_train,y_train)\n",
    "random_forest_pred=model_random_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89         5\n",
      "           1       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.90        10\n",
      "   macro avg       0.92      0.90      0.90        10\n",
      "weighted avg       0.92      0.90      0.90        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,random_forest_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9b025add082eba9f465bb7a51d61eaafbf35b7a16776511b49a7c1679204e3ae"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
